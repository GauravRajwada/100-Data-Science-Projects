{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and analysis of crime\n",
    "Part of Project Safest way \n",
    "  -Satyam Bhardwaj\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Imputer' from 'sklearn.preprocessing' (C:\\Users\\SATYAM\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-facaa305e8e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImputer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Imputer' from 'sklearn.preprocessing' (C:\\Users\\SATYAM\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd # panda's nickname is pd\n",
    "import numpy as np\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from  sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.preprocessing import binarize\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn import linear_model\n",
    "from IPython.display import Image \n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import tree\n",
    "import sklearn.preprocessing as prep\n",
    "import pydotplus \n",
    "import math\n",
    "from sklearn.linear_model import RidgeCV\n",
    "import sklearn.linear_model as linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "communities-crime-clean.csv file loaded into a dataframe object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_crime_df = pd.read_csv('communities-crime-clean.csv')\n",
    "\n",
    "# Sanity test we have good data\n",
    "communities_crime_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Trees\n",
    "Creating a new field “highCrime” which is true if the crime rate per capita (ViolentCrimesPerPop) is greater than 0.1, and false otherwise. here are percentage of positive and negative instances in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highCrime\n",
      "False    37.280482\n",
      "True     62.719518\n",
      "dtype: float64\n",
      "------------------\n",
      "Percentage Positive Instance = 62.719518314099346\n",
      "Percentage Negative Instance = 37.280481685900654 \n"
     ]
    }
   ],
   "source": [
    "def setHighCrime(df):\n",
    "    '''Function to set value of highCrime depending on ViolentCrimesPerPop'''\n",
    "    if df['ViolentCrimesPerPop'] > 0.1:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "# Adding a new field \"highCrime\"\n",
    "communities_crime_df['highCrime'] = communities_crime_df.apply(setHighCrime, axis=1)\n",
    "\n",
    "# Calculating the percentage of positive and negative instances in the dataset\n",
    "percentage_intances = communities_crime_df.groupby('highCrime').size() * 100 / len(communities_crime_df)\n",
    "print(percentage_intances)\n",
    "print(\"------------------\")\n",
    "print(\"Percentage Positive Instance = {}\\nPercentage Negative Instance = {} \".format(percentage_intances[1],percentage_intances[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DecisionTreeClassifier to learn a decision tree to predict highCrime on the entire dataset  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 1.0 Precision = 1.0 Recall = 1.0\n"
     ]
    }
   ],
   "source": [
    "#Dropping non-predictive fields as well as ViolentCrimesPerPop field \n",
    "X = communities_crime_df.drop('ViolentCrimesPerPop', axis=1).drop('state', axis=1).drop('communityname', axis=1).drop('fold', axis=1).drop('highCrime', axis=1)\n",
    "features = list(X.columns)\n",
    "y = communities_crime_df[\"highCrime\"]\n",
    "\n",
    "\n",
    "# First, we tried by not defining the max depth\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X,y)\n",
    "predicted = dt_clf.predict(X[features])\n",
    "recall_score = metrics.recall_score(communities_crime_df['highCrime'], predicted)\n",
    "precision_score = metrics.precision_score(communities_crime_df['highCrime'], predicted)\n",
    "accuracy_score = metrics.accuracy_score(communities_crime_df['highCrime'], predicted)\n",
    "print(\"Training Accuracy = {} Precision = {} Recall = {}\".format(accuracy_score,precision_score,recall_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Values of scores shows overfitting therefore we can define max_depth to avoid the complexity of the tree and to reach a point from where there is a decrease in the cross validation performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 1 Accuracy: 0.761\n",
      "Depth: 2 Accuracy: 0.776\n",
      "Depth: 3 Accuracy: 0.798\n",
      "Depth: 4 Accuracy: 0.790\n",
      "Depth: 5 Accuracy: 0.779\n",
      "Depth: 6 Accuracy: 0.768\n",
      "Depth: 7 Accuracy: 0.763\n",
      "Depth: 8 Accuracy: 0.746\n",
      "Depth: 9 Accuracy: 0.744\n"
     ]
    }
   ],
   "source": [
    "for depth in range(1,10):\n",
    "    tree_clf = DecisionTreeClassifier(max_depth=depth, random_state=0)\n",
    "    if tree_clf.fit(X,y).tree_.max_depth < depth:\n",
    "        break\n",
    "    score = np.mean(cross_val_score(tree_clf, X, y,scoring='accuracy', cv=10, n_jobs=1))\n",
    "    print(\"Depth: %i Accuracy: %.3f\" % (depth,score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the point up to which the performance is increasing is the depth 3. We can specify the depth and witness the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for DT = 0.83592574009\n",
      "Precision for DT = 0.900260190807\n",
      "Recall for DT = 0.900260190807\n"
     ]
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(max_depth=3)\n",
    "dt_clf.fit(X,y)\n",
    "#Predicting \n",
    "pred_dt= dt_clf.predict(X)\n",
    "dt_accuracy= metrics.accuracy_score(communities_crime_df['highCrime'], pred_dt)\n",
    "dt_precision= metrics.precision_score(communities_crime_df['highCrime'], pred_dt)\n",
    "dt_recall= metrics.recall_score(communities_crime_df['highCrime'], pred_dt)\n",
    "print(\"Accuracy for DT =\",dt_accuracy)\n",
    "print(\"Precision for DT =\",dt_precision)\n",
    "print(\"Recall for DT =\",dt_precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main features used for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-50bb8f108520>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdot_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tree' is not defined"
     ]
    }
   ],
   "source": [
    "dot_data = tree.export_graphviz(dt_clf, out_file=None,feature_names=list(X))\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "Image(graph.create_png()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a87482b44fd9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# more important the feature would be.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# We can sort the importance scores in descending order and take the top most.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mimportances\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdt_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimportances\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Printing the feature ranking\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dt_clf' is not defined"
     ]
    }
   ],
   "source": [
    "# checking the main features used for classification by checking the feature importance, the higher the value,\n",
    "# more important the feature would be.\n",
    "# We can sort the importance scores in descending order and take the top most.\n",
    "importances=dt_clf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# Printing the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "# We have taken the top 5 feature \n",
    "print(\"The main features used for classification\")\n",
    "print(X.columns[indices[:5]])\n",
    "print(\"Top main feature is\",X.columns[indices[:1]][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top main feature is PctKids2Par because it is the split point of the tree. This feature depicts the kids with two parents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying cross-validation (cross_val_score) to do 10-fold cross-validation to estimate the out-of-training accuracy of decision tree learning for this task.  \n",
    "10-fold cross-validation accuracy, precision, and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt_clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-87c4b1513907>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Applying 10 fold cross validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdt_cv_accuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdt_cv_precision\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdt_cv_recall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdt_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'recall'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cross Validation Accuracy DT:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt_cv_accuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dt_clf' is not defined"
     ]
    }
   ],
   "source": [
    "# Applying 10 fold cross validation\n",
    "dt_cv_accuracy = cross_val_score(dt_clf, X, y, cv=10).mean()\n",
    "dt_cv_precision= cross_val_score(dt_clf, X, y, cv=10, scoring='precision').mean()\n",
    "dt_cv_recall = cross_val_score(dt_clf, X, y, cv=10, scoring='recall').mean()\n",
    "print(\"Cross Validation Accuracy DT:\", dt_cv_accuracy)\n",
    "print(\"Cross Validation Recall DT:\", dt_cv_precision)\n",
    "print(\"Cross Validation Precision DT:\", dt_cv_recall)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use cross-validation to get a better estimate of the generalization error on new unseen data where as the common problem that is in Decision trees is overfitting, in which many training examples are fitting the training data perfectly or nearly perfectly which leads to an overly specific model and lower performance. Thus, we\n",
    "contrained the tree to include only up to three levels, since a simple tree is more general. Thus, the results obtained after specifying are more realistic.\n",
    "These results are different from cross validation results as the train and test data are different in cross validation on the other hand DT train on all the exmaples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Classification\n",
    "a. Using GaussianNB to learn a Naive Bayes classifier to predict highCrime.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-bbc2fcabce96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Using GaussianNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgaussian_clf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgaussian_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Applying 10 fold cross validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# Using GaussianNB\n",
    "gaussian_clf = GaussianNB()\n",
    "gaussian_clf.fit(X, y)\n",
    "\n",
    "# Applying 10 fold cross validation\n",
    "gaussian_accuracy = cross_val_score(gaussian_clf, X, y, cv=10).mean()\n",
    "gaussian_precision= cross_val_score(gaussian_clf, X, y, cv=10, scoring='precision').mean()\n",
    "gaussian_recall = cross_val_score(gaussian_clf, X, y, cv=10, scoring='recall').mean()\n",
    "print(\"Accuracy for gaussian :\", gaussian_accuracy)\n",
    "print(\"Recall for gaussian:\", gaussian_recall)\n",
    "print(\"Precision for gaussian:\", gaussian_precision)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10 most predictive feature :\n",
    "measured by the normalized absolute difference of means for\n",
    "the feature between the two classes:\n",
    "|𝜇𝑇 − 𝜇𝐹|/𝜎𝑇 + 𝜎𝐹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'communities_crime_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-2880595fd69f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_predictiveFeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcommunities_crime_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'state'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'communityname'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'fold'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdictPredFeature\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Collecting data for the two classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrue_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_predictiveFeature\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'highCrime'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'communities_crime_df' is not defined"
     ]
    }
   ],
   "source": [
    "df_predictiveFeature = communities_crime_df.drop('state', axis=1).drop('communityname', axis=1).drop('fold', axis=1)\n",
    "\n",
    "dictPredFeature = {}\n",
    "# Collecting data for the two classes\n",
    "true_df = X[df_predictiveFeature['highCrime'] == 1]\n",
    "false_df = X[df_predictiveFeature['highCrime'] == 0]\n",
    "for column in X:\n",
    "    mean_true = true_df[column].mean()\n",
    "    mean_false = false_df[column].mean()\n",
    "    var_true = true_df[column].var()\n",
    "    var_false = false_df[column].var()\n",
    "    if(column != 'highCrime'):\n",
    "        predScore = abs((mean_true - mean_false))/(math.sqrt(var_true)+math.sqrt(var_false))\n",
    "        dictPredFeature[column] = predScore\n",
    "most_pred_features = sorted(dictPredFeature.items(), key=lambda x: x[1])[-10:]\n",
    "for i in most_pred_features:\n",
    "    print(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have plotted the results obtained.  \n",
    "\n",
    "As it can be seen that the accuracy and recall are higher in case of Decision Trees but the precision is higher in case of Gaussian NB.\n",
    "I have to consider different criteria for choosing a classifier depending upon what is being  predicting. Accuracy is not always the most appropriate method to choose the classifier. Here, in case of Crime Prediction, Precision would be the best criteria to compare and it is higher in case of Gaussian NB so the results are better in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt_cv_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d64bf9ee6ef5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"DT\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m\"GaussianNB\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0macc_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdt_cv_accuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgaussian_accuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpre_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdt_cv_precision\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgaussian_precision\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mre_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdt_cv_recall\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgaussian_recall\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dt_cv_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "labels = [\"DT\" ,\"GaussianNB\"]\n",
    "acc_list = [dt_cv_accuracy,gaussian_accuracy]\n",
    "pre_list = [dt_cv_precision,gaussian_precision]\n",
    "re_list = [dt_cv_recall,gaussian_recall]\n",
    "\n",
    "x_axis_range = range(2)\n",
    "plt.xticks(x_axis_range, labels, rotation='vertical')\n",
    "# plt.legend()\n",
    "\n",
    "plt.plot(x_axis_range,acc_list,'ro',color=\"Red\",label=\"Accuracy\")\n",
    "plt.plot(x_axis_range,pre_list,'>',color=\"green\",label=\"Precision\")\n",
    "plt.plot(x_axis_range,re_list,'<',color=\"green\",label=\"Recall\")\n",
    "\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Metrics')\n",
    "plt.margins(0.2)\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "legend = plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Using LinearSVC to learn a linear Support Vector Machine model to predict highCrime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c6afe4094372>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlinearsvmclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccuracy_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinearsvmclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprecision_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinearsvmclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'precision'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mrecall_svm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinearsvmclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'recall'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy for LinearSVC is'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_svm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "linearsvmclf = svm.SVC(kernel='linear', C =1.0)\n",
    "accuracy_svm = cross_val_score(linearsvmclf, X, y, cv=10, scoring='accuracy').mean()\n",
    "precision_svm = cross_val_score(linearsvmclf, X, y, cv=10, scoring='precision').mean()\n",
    "recall_svm = cross_val_score(linearsvmclf, X, y, cv=10, scoring='recall').mean()\n",
    "print ('Accuracy for LinearSVC is', accuracy_svm)\n",
    "print ('Precision for LinearSVC is', precision_svm)\n",
    "print ('Recall for LinearSVC is', recall_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-1b9bf5cd15ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlinearsvmclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlinearsvmclf_coef_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "linearsvmclf.fit(X,y)\n",
    "\n",
    "linearsvmclf_coef_array = {}\n",
    "count = 0\n",
    "for i in X.columns:\n",
    "    linearsvmclf_coef_array[i] = abs(linearsvmclf.coef_[0][count])\n",
    "    count = count+ 1\n",
    "\n",
    "most_predictive_features = sorted(linearsvmclf_coef_array.items(), key=lambda x: x[1])[-10:]\n",
    "most_predictive_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have plotted the results obtained from linear SVM and DT.  \n",
    "As it can seen that the accuracy and recall are higher in case of Decision Trees but the precision is higher in case of linear SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dt_cv_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-65f32c606bba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"DT\"\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m\"LinearSVC\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0macc_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdt_cv_accuracy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy_svm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpre_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdt_cv_precision\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mprecision_svm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mre_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdt_cv_recall\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrecall_svm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dt_cv_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "labels = [\"DT\" ,\"LinearSVC\"]\n",
    "acc_list = [dt_cv_accuracy,accuracy_svm]\n",
    "pre_list = [dt_cv_precision,precision_svm]\n",
    "re_list = [dt_cv_recall,recall_svm]\n",
    "\n",
    "x_axis_range = range(2)\n",
    "plt.xticks(x_axis_range, labels, rotation='vertical')\n",
    "# plt.legend()\n",
    "\n",
    "plt.plot(x_axis_range,acc_list,'ro',color=\"Red\",label=\"Accuracy\")\n",
    "plt.plot(x_axis_range,pre_list,'>',color=\"green\",label=\"Precision\")\n",
    "plt.plot(x_axis_range,re_list,'<',color=\"green\",label=\"Recall\")\n",
    "\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Metrics')\n",
    "plt.margins(0.2)\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "legend = plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Regression\n",
    "a. Use LinearRegression to learn a linear model directly predicting the crime rate per capita (ViolentCrimesPerPop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated meansquared- error (MSE) of the model is 0.0200939693044\n"
     ]
    }
   ],
   "source": [
    "Y = communities_crime_df['ViolentCrimesPerPop']\n",
    "linear_regression = LinearRegression()\n",
    "#df = df.drop('highCrime', 1)\n",
    "mean_sq_err= cross_val_score(linear_regression,X, Y,None,scoring='neg_mean_squared_error',cv=10)\n",
    "print(\"Estimated meansquared- error (MSE) of the model is\",np.abs(mean_sq_err.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on the training set is 0.016516774880307207\n"
     ]
    }
   ],
   "source": [
    "linear_regression.fit(X,Y)\n",
    "print(\"MSE on the training set is {}\".format(np.mean((linear_regression.predict(X) - Y) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most predictive features can be checked by checking the coefficients, the larger the coeff, more predictive the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Predictive Feature of a High Crime Rate is PersPerOccupHous\n",
      "Most Predictive Feature of a Low Crime Rate is PctPersOwnOccup\n"
     ]
    }
   ],
   "source": [
    "# Taking the coefficients in an array\n",
    "list_coef = np.array(linear_regression.coef_)\n",
    "\n",
    "\n",
    "print(\"Most Predictive Feature of a High Crime Rate is\", X.columns[np.argmax(list_coef)])\n",
    "print(\"Most Predictive Feature of a Low Crime Rate is\", X.columns[np.argmin(list_coef)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b.Now use Ridge regression to reduce the amount of overfitting, using RidgeCV to pick the best alpha from among (10, 1, 0.1, 0.01, and 0.001).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha 1.0\n"
     ]
    }
   ],
   "source": [
    "clf = RidgeCV(alphas=(10, 1, 0.1, 0.01, 0.001))\n",
    "clf.fit(X, Y)\n",
    "print(\"Best alpha\", clf.alpha_)  \n",
    "\n",
    "#Other way to find out best aplha \n",
    "#alphas = np.array([10, 1, 0.1, 0.01, 0.001])\n",
    "#model = Ridge()\n",
    "#grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "#grid.fit(X, Y)\n",
    "#print(grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### i. What is the estimated MSE of the model under 10-fold CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated meansquared- error (MSE) of the model is 0.0197950213482\n"
     ]
    }
   ],
   "source": [
    "ridge_clf = linear_model.Ridge(alpha=1.0)\n",
    "ridge_clf.fit(X,Y)\n",
    "mean_sq_err= cross_val_score(ridge_clf,X, Y,None,scoring='neg_mean_squared_error',cv=10)\n",
    "print(\"Estimated meansquared- error (MSE) of the model is\",np.abs(mean_sq_err.mean()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ii. What is the MSE on the training set (train on all the data then test on it all)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on the training set is 0.02\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"MSE on the training set is {0:0.2f}\".format(np.mean((ridge_clf.predict(X) - Y) ** 2)))\n",
    "\n",
    "#ridge_reg=linear_model.Ridge(alpha = 0.001)\n",
    "#ridge_reg.fit(X,Y)\n",
    "\n",
    "#print(\"Mean squared error: %.2f\"\n",
    "#      % np.mean((ridge_reg.predict(X) - Y) ** 2))\n",
    "#print(\"MSE on the training set is {}\".format(np.mean((ridge_reg.predict(X) - Y) ** 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  iii. What is the best alpha?\n",
    "We have calculate the best alpha using RidgeCV and re-verified by using GridSearchCV.  \n",
    "\n",
    "The best alpha is 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### iv. What does this say about the amount of overfitting in linear regression for this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Now use polynomial features to do quadratic (second-order) polynomial regression.\n",
    "##### i.What is the estimated MSE of the model under 10-fold CV?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated MSE of the model under 10-fold CV is 0.129900201476\n"
     ]
    }
   ],
   "source": [
    "poly_feature = PolynomialFeatures(degree  = 2, interaction_only = False)\n",
    "poly_df = poly_feature.fit_transform(X)\n",
    "ridge_clf.fit(poly_df,y)\n",
    "## caluclating MSE\n",
    "poly_mse= cross_val_score(linear_regression, poly_df, Y,None,scoring='neg_mean_squared_error',cv=10)\n",
    "print(\"Estimated MSE of the model under 10-fold CV is\",np.abs(poly_mse.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.23\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Mean squared error: %.2f\" % np.mean((ridge_clf.predict(poly_df) - Y) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Does this mean the quadratic model is better than the linear model for this problem?\n",
    "Polynomial Regression is not better than the linear model as the MSE is higher in this case if we compare the value of polynomial regression MSE which is 0.3 to the value of linear SVC mSE which is 0.02."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Dirty Data\n",
    "#### Repeat the decision tree learning question for the full (non-clean) data set and present the results.\n",
    "#### a. Are the CV results better or worse? What does this say about the effect of missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dirty data\n",
    "df_d = pd.read_csv('communities-crime-full.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highCrime\n",
      "False    37.261785\n",
      "True     62.738215\n",
      "dtype: float64\n",
      "------------------\n",
      "Percentage Positive Instance = 62.7382146439318\n",
      "Percentage Negative Instance = 37.2617853560682 \n"
     ]
    }
   ],
   "source": [
    "# Making data clean \n",
    "\n",
    "df_d_clean = df_d.replace('?', np.nan)\n",
    "df_d_clean = df_d_clean.drop('community', axis=1).drop('state', axis=1).drop('communityname', axis=1).drop('fold', axis=1).drop('county', axis=1)\n",
    "cols_numeric = df_d_clean.columns\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "Y = imp.fit_transform(df_d_clean)\n",
    "df_d_clean = pd.DataFrame(Y)\n",
    "df_d_clean.columns = cols_numeric\n",
    "df_d_clean['highCrime'] = df_d_clean.apply(setHighCrime, axis=1)\n",
    "\n",
    "percentage_intances = df_d_clean.groupby('highCrime').size() * 100 / len(df_d_clean)\n",
    "print(percentage_intances)\n",
    "print(\"------------------\")\n",
    "print(\"Percentage Positive Instance = {}\\nPercentage Negative Instance = {} \".format(percentage_intances[1],percentage_intances[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy = 0.8360080240722166 Precision = 0.9003466204506065 Recall = 0.8305355715427658\n"
     ]
    }
   ],
   "source": [
    "y = df_d_clean[\"highCrime\"]\n",
    "X = df_d_clean.drop('highCrime', axis=1).drop('ViolentCrimesPerPop', axis=1)\n",
    "\n",
    "# taking max_depth 3 to avoid overfitting \n",
    "dt = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "dt.fit(X,y)\n",
    "predicted = dt.predict(X)\n",
    "\n",
    "recall_score = metrics.recall_score(df_d_clean['highCrime'], predicted)\n",
    "precision_score = metrics.precision_score(df_d_clean['highCrime'], predicted)\n",
    "accuracy_score = metrics.accuracy_score(df_d_clean['highCrime'], predicted)\n",
    "\n",
    "print(\"Training Accuracy = {} Precision = {} Recall = {}\".format(accuracy_score,precision_score,recall_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "[44  3  5 71 39]\n",
      "Index(['PctKids2Par', 'racePctWhite', 'racePctHisp', 'HousVacant',\n",
      "       'MalePctNevMarr'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# We can check the main features used for classification by checking the feature importnaces, the higher the value,\n",
    "# more important the feature would be.\n",
    "# We can sort the impostamce scores in descending order and take the top most.\n",
    "importances=dt.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "print(indices[:5])\n",
    "print(X.columns[indices[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results after applying 10-fold cross-validation\n",
      "Accuracy: 0.81 (+/- 0.02)\n",
      "Recall 0.817777777778\n",
      "Precision 0.877539377831\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(dt, X, y, cv=10)\n",
    "\n",
    "precision= cross_val_score(dt, X, y, cv=10, scoring='precision')\n",
    "recal = cross_val_score(dt, X, y, cv=10, scoring='recall')\n",
    "print(\"Results after applying 10-fold cross-validation\")\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std()))\n",
    "print(\"Recall\", np.mean(recal))\n",
    "print(\"Precision\", np.mean(precision))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a. Are the CV results better or worse? What does this say about the effect of missing values?\n",
    "The CV results are a tad better in clean data as compared to the dirty data.In case of dirty data we have replaced the missing values by mean so nothing can be said about those."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Team Work\n",
    "### We have taken two learning methods: Polynomial Kernel and K means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i. Experiment with two learning methods other than those described above (one can be a non-linear kernel for SVM) for\n",
    "the classification problem, explaining clearly what you did.Show CV results for both the clean and full datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for polynomial(Dirty Data) is 0.832994174854\n",
      "Precision for polynomial(Dirty Data) is 0.867708277094\n",
      "Recall for polynomial(Dirty Data) is 0.866507936508\n"
     ]
    }
   ],
   "source": [
    "# Applying polynomial Kernel SVC\n",
    "poly_clf = svm.SVC(kernel='poly', degree=2, C= 50)\n",
    "X_d = X\n",
    "y_d = y\n",
    "# For large values of C, the optimization will choose a smaller-margin hyperplane if that hyperplane does a better job of getting all the training points classified correctly.\n",
    "# non clean dataset \n",
    "poly_accuracy_d = cross_val_score(poly_clf, X_d, y_d, cv=10, scoring='accuracy').mean()\n",
    "poly_precision_d = cross_val_score(poly_clf, X_d, y_d, cv=10, scoring='precision').mean()\n",
    "poly_recall_d = cross_val_score(poly_clf, X_d, y_d, cv=10, scoring='recall').mean()\n",
    "\n",
    "print ('Accuracy for polynomial(Dirty Data) is', poly_accuracy_d)\n",
    "print ('Precision for polynomial(Dirty Data) is', poly_precision_d)\n",
    "print ('Recall for polynomial(Dirty Data) is', poly_recall_d)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for polynomial(Clean Data) is 0.807271356784\n",
      "Precision for polynomial(Clean Data) is 0.854945616904\n",
      "Recall for polynomial(Clean Data) is 0.8448\n"
     ]
    }
   ],
   "source": [
    "# clean dataset\n",
    "X = communities_crime_df.drop('ViolentCrimesPerPop', axis=1).drop('state', axis=1).drop('communityname', axis=1).drop('fold', axis=1).drop('highCrime', axis=1)\n",
    "features = list(X.columns)\n",
    "y = communities_crime_df[\"highCrime\"]\n",
    "\n",
    "poly_accuracy = cross_val_score(poly_clf, X, y, cv=10, scoring='accuracy').mean()\n",
    "poly_precision = cross_val_score(poly_clf, X, y, cv=10, scoring='precision').mean()\n",
    "poly_recall = cross_val_score(poly_clf, X, y, cv=10, scoring='recall').mean()\n",
    "\n",
    "print ('Accuracy for polynomial(Clean Data) is', poly_accuracy)\n",
    "print ('Precision for polynomial(Clean Data) is', poly_precision)\n",
    "print ('Recall for polynomial(Clean Data) is', poly_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for KMeans(Dirty data) is 0.384595477387\n",
      "Precision for KMeans(Dirty data) is 0.636187500137\n",
      "Recall for KMeans(Dirty data) is 0.55086412992\n"
     ]
    }
   ],
   "source": [
    "#clf = KMeans(n_clusters = 2)\n",
    "km_clf = KMeans(n_clusters = 2)\n",
    "km_accuracy_d = cross_val_score(km_clf, X_d, y_d, cv=10, scoring='accuracy').mean()\n",
    "km_precision_d = cross_val_score(km_clf, X_d, y_d, cv=10, scoring='precision').mean()\n",
    "km_recall_d = cross_val_score(km_clf, X_d, y_d, cv=10, scoring='recall').mean()\n",
    "\n",
    "print ('Accuracy for KMeans(Dirty data) is', km_accuracy_d)\n",
    "print ('Precision for KMeans(Dirty data) is', km_precision_d)\n",
    "print ('Recall for KMeans(Dirty data) is', km_recall_d)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is for KMeans(Clean data) 0.406989949749\n",
      "Precision is for KMeans(Clean data) 0.612484172735\n",
      "Recall is for KMeans(Clean data) 0.513012817885\n"
     ]
    }
   ],
   "source": [
    "\n",
    "km_accuracy = cross_val_score(km_clf, X, y, cv=10, scoring='accuracy').mean()\n",
    "km_precision = cross_val_score(km_clf, X, y, cv=10, scoring='precision').mean()\n",
    "km_recall = cross_val_score(km_clf, X, y, cv=10, scoring='recall').mean()\n",
    "\n",
    "print ('Accuracy is for KMeans(Clean data)', km_accuracy)\n",
    "print ('Precision is for KMeans(Clean data)', km_precision)\n",
    "print ('Recall is for KMeans(Clean data)', km_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAE0CAYAAADDtS+YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzMws41AwM7OMQ8HMzDL/C9/ZSDaXzsIjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1fb18c6b908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names = [\"Nonlinear SVM\" ,\"K Means\"]\n",
    "acc_list = [poly_accuracy,km_accuracy]\n",
    "pre_list = [poly_precision,km_precision]\n",
    "re_list = [poly_recall,km_recall]\n",
    "xaxisRange = range(2)\n",
    "plt.xticks(xaxisRange, names, rotation=45)\n",
    "# plt.legend()\n",
    "\n",
    "plt.plot(xaxisRange,acc_list,'ro',color=\"Red\",label=\"Accuracy\")\n",
    "plt.plot(xaxisRange,pre_list,'>',color=\"green\",label=\"Precision\")\n",
    "plt.plot(xaxisRange,pre_list,'<',color=\"green\",label=\"Recall\")\n",
    "\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Metrics')\n",
    "plt.margins(0.2)\n",
    "plt.subplots_adjust(bottom=0.15)\n",
    "legend = plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. What method gives the best results?  \n",
    "Clearly the Nonlinear SVM has better results for metrics as compared to the other model which is K means."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iii. What feature(s) seem to be most consistently predictive of high crime rates? How reliable is this conclusion?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for GradientBoostingClassifier(Dirty Data) is 0.838989249731\n",
      "Precision for GradientBoostingClassifier(Dirty Data) is 0.874019434226\n",
      "Recall for GradientBoostingClassifier(Dirty Data) is 0.868095238095\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(X_d, y_d)\n",
    "#dirty dataset\n",
    "acc_scores = cross_val_score(clf, X_d, y_d, cv=10, scoring='accuracy').mean()\n",
    "pre_scores = cross_val_score(clf, X_d, y_d, cv=10, scoring='precision').mean()\n",
    "rec_scores = cross_val_score(clf, X_d, y_d, cv=10, scoring='recall').mean()\n",
    "print ('Accuracy for GradientBoostingClassifier(Dirty Data) is', acc_scores)\n",
    "print ('Precision for GradientBoostingClassifier(Dirty Data) is', pre_scores)\n",
    "print ('Recall for GradientBoostingClassifier(Dirty Data) is', rec_scores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy GradientBoostingClassifier(Clean Data) is 0.80072361809\n",
      "Precision GradientBoostingClassifier(Clean Data)is 0.848806289998\n",
      "Recall is GradientBoostingClassifier(Clean Data) is  0.8352\n"
     ]
    }
   ],
   "source": [
    "#clean dataset\n",
    "clf.fit(X, y)\n",
    "acc_scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy').mean()\n",
    "pre_scores = cross_val_score(clf, X, y, cv=10, scoring='precision').mean()\n",
    "rec_scores = cross_val_score(clf, X, y, cv=10, scoring='recall').mean()\n",
    "print ('Accuracy GradientBoostingClassifier(Clean Data) is', acc_scores)\n",
    "print ('Precision GradientBoostingClassifier(Clean Data)is', pre_scores)\n",
    "print ('Recall is GradientBoostingClassifier(Clean Data) is ', rec_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for RandomForestClassifier is 0.817963874097\n",
      "Precision for RandomForestClassifier is 0.843663428685\n",
      "Recall for RandomForestClassifier is 0.872107936508\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=100, max_depth=3)\n",
    "\n",
    "rf_accuracy = cross_val_score(clf, X_d, y_d, cv=10, scoring='accuracy').mean()\n",
    "rf_precision = cross_val_score(clf, X_d, y_d, cv=10, scoring='precision').mean()\n",
    "rf_recall = cross_val_score(clf, X_d, y_d, cv=10, scoring='recall').mean()\n",
    "\n",
    "print ('Accuracy for RandomForestClassifier is', rf_accuracy)\n",
    "print ('Precision for RandomForestClassifier is', rf_precision)\n",
    "print ('Recall for RandomForestClassifier is', rf_recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Classifier shows good results in terms of metrics and would be a good model to predict the crime data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "\n",
    "We have applied various models including: Decision Trees, Gaussian NB, Linear VNM, Regression, Linear SVM, Non linear SVM, K means, Gradient Boosting Classifier and Random Forests. We also performed the 10 fold cross validation. The results are different and we have plotted results based on the metrics for the different models. It can further be tested on many models to identify the best that can be used to predict the crime rate."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
